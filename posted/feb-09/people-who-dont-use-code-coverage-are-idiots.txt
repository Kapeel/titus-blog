People who don't have 100% code coverage are idiots
# tags python,testing

My `last post, Good code coverage: Necessity vs Sufficiency
<http://ivory.idyll.org/blog/feb-09/necessity-vs-sufficiency.html>`__,
about how you should maintain high code coverage with your automated
tests, seems to have really struck a nerve in a small group of people
-- I got some fantastic comments, with some great pointers.  Michael
Foord's comment, 'Too often "testing is no silver bullet" is used as
an excuse not to test' hit the nail on the head, and Andrew Dalke
`linked to his excellent & detailed discussion with Glyph about code
coverage
<http://glyph.twistedmatrix.com/2009/02/joel-un-test.html>`__, as well
as pointing out `the SQLite testing policy
<http://www.sqlite.org/testing.html>`__ which is, frankly, astounding.

But I'm not writing this just to point out those links.  No, this is
partly in response to Ned Batchelder's plaintive question about why I
picked on him.  **I picked on him because of his article's title:
"there are flaws in coverage measurement."** Now, Ned is the author of
coverage, the main code coverage tool available for Python -- and I
*know* he thinks code coverage is really important.  And it is
entirely legitimate to write critical essays about code coverage,
especially statement coverage. But I also get frustrated with people
who write blog posts with even moderately sensational and
misrepresentative blog post titles.  And that's why I included him in
the post complaining about such things.

Got that?  **I hate sensational and misrepresentative titles.**

Good day.

--titus
